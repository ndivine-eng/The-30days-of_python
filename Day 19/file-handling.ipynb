{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./data/obama_speech.txt\n",
      "File not found: ./data/michelle_obama_speech.txt\n",
      "File not found: ./data/donald_speech.txt\n",
      "File not found: ./data/melina_trump_speech.txt\n"
     ]
    }
   ],
   "source": [
    "# Import the os module to check if files exist before reading\n",
    "import os  \n",
    "\n",
    "def count_lines_words(filename):\n",
    "    \"\"\"\n",
    "    Reads a text file and counts the number of lines and words.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (number_of_lines, number_of_words) in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the file in read mode with UTF-8 encoding\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()  # Read all lines into a list\n",
    "            words = ' '.join(lines).split()  # Join lines into a string, then split into words\n",
    "\n",
    "        # Return the count of lines and words\n",
    "        return len(lines), len(words)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If the file is missing, print an error message and return (0, 0)\n",
    "        print(f\"Error: {filename} not found.\")\n",
    "        return 0, 0\n",
    "\n",
    "# List of file paths to check\n",
    "files = [\n",
    "    './data/obama_speech.txt',\n",
    "    './data/michelle_obama_speech.txt',\n",
    "    './data/donald_speech.txt',\n",
    "    './data/melina_trump_speech.txt'\n",
    "]\n",
    "\n",
    "# Loop through each file in the list\n",
    "for file in files:\n",
    "    # Check if the file exists before attempting to open it\n",
    "    if os.path.exists(file):\n",
    "        # Call the function to count lines and words\n",
    "        lines, words = count_lines_words(file)\n",
    "        # Print the results\n",
    "        print(f\"{file}: {lines} lines, {words} words\")\n",
    "    else:\n",
    "        # If the file does not exist, print an error message\n",
    "        print(f\"File not found: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./data/countries_data.json\n",
      "File not found: ./data/countries_data.json\n"
     ]
    }
   ],
   "source": [
    "import json  # Import the JSON module to handle JSON files\n",
    "\n",
    "def most_populated_countries(filename, top_n):\n",
    "    \"\"\"\n",
    "    Reads a JSON file containing country data and returns the top N most populated countries.\n",
    "    \n",
    "    Parameters:\n",
    "    filename (str): Path to the JSON file.\n",
    "    top_n (int): Number of top populated countries to return.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing country names and their populations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open and read the JSON file\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            countries = json.load(file)  # Load the JSON data into a Python list\n",
    "\n",
    "        # Sort the list of countries based on the 'population' key in descending order\n",
    "        sorted_countries = sorted(countries, key=lambda x: x['population'], reverse=True)\n",
    "\n",
    "        # Extract the top N populated countries and return as a list of dictionaries\n",
    "        return [{'country': country['name'], 'population': country['population']} for country in sorted_countries[:top_n]]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case when the file is not found\n",
    "        return f\"File not found: {filename}\"\n",
    "\n",
    "# Example usage: Finding the 10 most populated countries\n",
    "print(most_populated_countries('./data/countries_data.json', 10))\n",
    "\n",
    "# Example usage: Finding the 3 most populated countries\n",
    "print(most_populated_countries('./data/countries_data.json', 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./data/countries_data.json\n",
      "File not found: ./data/countries_data.json\n"
     ]
    }
   ],
   "source": [
    "import json  # Import the JSON module to handle JSON files\n",
    "\n",
    "def most_populated_countries(filename, top_n):\n",
    "    \"\"\"\n",
    "    Reads a JSON file containing country data and returns the top N most populated countries.\n",
    "    \n",
    "    Parameters:\n",
    "    filename (str): Path to the JSON file.\n",
    "    top_n (int): Number of top populated countries to return.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing country names and their populations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open and read the JSON file\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            countries = json.load(file)  # Load the JSON data into a Python list\n",
    "\n",
    "        # Sort the list of countries based on the 'population' key in descending order\n",
    "        sorted_countries = sorted(countries, key=lambda x: x['population'], reverse=True)\n",
    "\n",
    "        # Extract the top N populated countries and return as a list of dictionaries\n",
    "        return [{'country': country['name'], 'population': country['population']} for country in sorted_countries[:top_n]]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case when the file is not found\n",
    "        return f\"File not found: {filename}\"\n",
    "\n",
    "# Example usage: Finding the 10 most populated countries\n",
    "print(most_populated_countries('./data/countries_data.json', 10))\n",
    "\n",
    "# Example usage: Finding the 3 most populated countries\n",
    "print(most_populated_countries('./data/countries_data.json', 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract All Incoming Email Addresses\n",
    "We will extract email addresses from email_exchange_big.txt using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./data/email_exchange_big.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_emails(filename):\n",
    "    \"\"\"\n",
    "    Extracts all email addresses from a given file.\n",
    "    \n",
    "    Parameters:\n",
    "    filename (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of unique email addresses.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Regular expression for extracting emails\n",
    "        emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', text)\n",
    "        \n",
    "        return list(set(emails))  # Return unique emails\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return f\"File not found: {filename}\"\n",
    "\n",
    "# Example usage\n",
    "emails = extract_emails('./data/email_exchange_big.txt')\n",
    "print(emails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the Most Common Words\n",
    "We will count word frequencies and return the n most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./data/sample.txt\n",
      "File not found: ./data/sample.txt\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def find_most_common_words(filename, n):\n",
    "    \"\"\"\n",
    "    Finds the most common words in a file.\n",
    "    \n",
    "    Parameters:\n",
    "    filename (str): The file to analyze.\n",
    "    n (int): Number of most common words to return.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples containing (frequency, word).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            text = file.read().lower()\n",
    "        \n",
    "        # Remove punctuation and split words\n",
    "        words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "        \n",
    "        # Count word frequencies\n",
    "        word_counts = Counter(words)\n",
    "        \n",
    "        return word_counts.most_common(n)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return f\"File not found: {filename}\"\n",
    "\n",
    "# Example usage\n",
    "print(find_most_common_words('./data/sample.txt', 10))\n",
    "print(find_most_common_words('./data/sample.txt', 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the Most Frequent Words in the Speeches\n",
    "We reuse find_most_common_words() for different speech files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent words in speeches\n",
    "print(\"Obama's Speech:\", find_most_common_words('./data/obama_speech.txt', 10))\n",
    "print(\"Michelle's Speech:\", find_most_common_words('./data/michelle_obama_speech.txt', 10))\n",
    "print(\"Trump's Speech:\", find_most_common_words('./data/donald_speech.txt', 10))\n",
    "print(\"Melina's Speech:\", find_most_common_words('./data/melina_trump_speech.txt', 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Similarity Between Two Texts\n",
    "We will:\n",
    "\n",
    "Clean the text (remove special characters and make lowercase)\n",
    "\n",
    "Remove stop words (common words that don’t add meaning)\n",
    "\n",
    "Compare text similarity (Jaccard similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Cleans text by removing punctuation and converting to lowercase.\"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    return text.split()\n",
    "\n",
    "def remove_support_words(words, stop_words_file):\n",
    "    \"\"\"Removes stop words from a list of words.\"\"\"\n",
    "    try:\n",
    "        with open(stop_words_file, 'r', encoding='utf-8') as file:\n",
    "            stop_words = set(file.read().split())\n",
    "\n",
    "        return [word for word in words if word not in stop_words]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return words  # If stop words file is missing, return the original list\n",
    "\n",
    "def check_text_similarity(file1, file2, stop_words_file):\n",
    "    \"\"\"\n",
    "    Checks the similarity between two texts using Jaccard similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    file1 (str): Path to first text file.\n",
    "    file2 (str): Path to second text file.\n",
    "    stop_words_file (str): Path to stop words file.\n",
    "\n",
    "    Returns:\n",
    "    float: Similarity percentage.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
    "            words1 = clean_text(f1.read())\n",
    "            words2 = clean_text(f2.read())\n",
    "\n",
    "        words1 = set(remove_support_words(words1, stop_words_file))\n",
    "        words2 = set(remove_support_words(words2, stop_words_file))\n",
    "\n",
    "        # Jaccard similarity: |A ∩ B| / |A ∪ B|\n",
    "        similarity = len(words1 & words2) / len(words1 | words2)\n",
    "\n",
    "        return round(similarity * 100, 2)  # Convert to percentage\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"One of the files not found.\"\n",
    "\n",
    "# Example: Checking similarity between Michelle's and Melina's speeches\n",
    "print(check_text_similarity('./data/michelle_obama_speech.txt', './data/melina_trump_speech.txt', './data/stop_words.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 10 Most Repeated Words in romeo_and_juliet.txt\n",
    "We can use the find_most_common_words() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./data/romeo_and_juliet.txt\n"
     ]
    }
   ],
   "source": [
    "print(find_most_common_words('./data/romeo_and_juliet.txt', 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the Hacker News CSV File\n",
    "We need to count lines containing specific keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines containing 'Python': File not found: ./data/hacker_news.csv\n",
      "Lines containing 'JavaScript': File not found: ./data/hacker_news.csv\n",
      "Lines containing 'Java' but NOT 'JavaScript': File not found: ./data/hacker_news.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def count_keyword_occurrences(filename, keyword, exclude=None):\n",
    "    \"\"\"\n",
    "    Counts the number of lines containing a keyword in a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    filename (str): Path to the CSV file.\n",
    "    keyword (str): The keyword to search for.\n",
    "    exclude (str, optional): A word to exclude if present in the line.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of matching lines.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        count = 0\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                line = ' '.join(row).lower()\n",
    "                if keyword.lower() in line:\n",
    "                    if exclude and exclude.lower() in line:\n",
    "                        continue\n",
    "                    count += 1\n",
    "        return count\n",
    "    except FileNotFoundError:\n",
    "        return f\"File not found: {filename}\"\n",
    "\n",
    "# Count occurrences\n",
    "python_count = count_keyword_occurrences('./data/hacker_news.csv', 'python')\n",
    "javascript_count = count_keyword_occurrences('./data/hacker_news.csv', 'javascript')\n",
    "java_count = count_keyword_occurrences('./data/hacker_news.csv', 'java', exclude='javascript')\n",
    "\n",
    "print(f\"Lines containing 'Python': {python_count}\")\n",
    "print(f\"Lines containing 'JavaScript': {javascript_count}\")\n",
    "print(f\"Lines containing 'Java' but NOT 'JavaScript': {java_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
